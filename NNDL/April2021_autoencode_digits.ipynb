{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "April2021 autoencode_digits.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElenaPocaterra/MLNPS2021/blob/main/NNDL/April2021_autoencode_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4Hqug0lfaG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "982059e2-0e3c-4707-d0d4-6b78ed67f1ba"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense#, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import glob\n",
        "import pylab as pl\n",
        "from PIL import Image\n",
        "\n",
        "%pylab inline\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['ndim']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8mW27gnf7U4"
      },
      "source": [
        "# 1. change kernel to GPU \n",
        "go to runtime -> change runtime type -> GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPgi-4gMgRTo"
      },
      "source": [
        "# digits first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3UsLpN7gRJy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "7c3e9d06-c0d1-48a8-b76a-8d4e7d6f2deb"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "pl.imshow(x_train[0])\n",
        "pl.axis('off')\n",
        "intialshape = x_train[0].shape\n",
        "ndim = np.prod(x_train[0].shape)\n",
        "print(intialshape)\n",
        "print(ndim)\n",
        "x_train.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n",
            "784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kgzSExkgQ9Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a9f1049-9dee-41b5-9f3d-7d9152f5d46e"
      },
      "source": [
        "x_train.dtype, x_train.max(), x_train.min()\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('uint8'), 255, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsF_Zzafqntr",
        "outputId": "c62342a3-cf58-4955-fc4d-0505ee9c1cec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "pl.imshow(x_test[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb0b11c2950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KhWi6TGhdv1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0650499f-9c03-4fa1-d80b-bb4fc353912f"
      },
      "source": [
        "x_train = (x_train.astype(float) / 255).reshape(len(x_train), ndim)\n",
        "x_test = (x_test.astype(float) / 255).reshape(len(x_test), ndim)\n",
        "x_train.shape, x_test.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huWbhFyJK4Vn"
      },
      "source": [
        "# create a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zR7X6JuK7WW"
      },
      "source": [
        "keras.models?"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_46wAeZBl8f"
      },
      "source": [
        "Dense?"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eheFp_InJiao",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e928affc-717b-449d-f464-e148f9c0b0d1"
      },
      "source": [
        "model_digits64 = Sequential()\n",
        "## encoder\n",
        "# input layer and the output size\n",
        "model_digits64.add(Dense(128, activation='relu',batch_size = None, input_dim=784)) #input_dim per importare immagine appiattita(1D). input_shape per importare immagine 2D.\n",
        "#compression layer\n",
        "model_digits64.add(Dense(64, activation='relu'))\n",
        "## deencoder\n",
        "#decompression layer, same size as in the encoder\n",
        "model_digits64.add(Dense(128, activation='relu'))\n",
        "#output layer, same size as input\n",
        "model_digits64.add(Dense(ndim, activation='linear'))\n",
        "\n",
        "\n",
        "#alternative syntax\n",
        "\"\"\"\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "encoder = Model(input_img, encoded)\n",
        "\n",
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "# retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# create the decoder model\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
        "\"\"\""
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nencoded = Dense(encoding_dim, activation=\\'relu\\')(input_img)\\n# \"decoded\" is the lossy reconstruction of the input\\ndecoded = Dense(784, activation=\\'sigmoid\\')(encoded)\\n\\nautoencoder = Model(input_img, decoded)\\n\\nencoder = Model(input_img, encoded)\\n\\n# create a placeholder for an encoded (32-dimensional) input\\nencoded_input = Input(shape=(encoding_dim,))\\n# retrieve the last layer of the autoencoder model\\ndecoder_layer = autoencoder.layers[-1]\\n# create the decoder model\\ndecoder = Model(encoded_input, decoder_layer(encoded_input))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-jfXI90M0yE"
      },
      "source": [
        "### regression\n",
        "- loss='mean_squared_error' L2: default loss to use for regression problems. => linear activation function in output layer, one node out\n",
        "\n",
        "alternatives:  loss='mean_squared_logarithmic_error', 'mean_absolute_error' (which is L1 instead of L2)\n",
        "### binary classification\n",
        "\n",
        "- loss='binary_crossentropy' => sigmoid activation function in output layer, one node out\n",
        "\n",
        "alternatives: 'hinge'\n",
        "\n",
        "### multiclass classification\n",
        "categorical encoded as numerical\n",
        "- loss='categorical_crossentropy' => softmax n nodes out\n",
        "\n",
        "onehot encoded categoridal\n",
        "- 'parse_categorical_crossentropy' => softmax n nodes out\n",
        "\n",
        "- 'kullback Leibler Divergence Loss' => probabilistic categorical classification; log(P/Q)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZORHj6SPha0"
      },
      "source": [
        "## optimizers\n",
        "- SGD: stocastic gradient descent \n",
        "    - nesterov=True -> momentum inclusion\n",
        "- adam: Adaptive moment estimation. **good in most cases**\n",
        "- adagrad: different steps for different parameters based on frequency (binary input) well-suited for dealing with sparse data.\n",
        "\n",
        "- adaDelta: like adagrad but compensated for vanishing learning rate problem\n",
        "\n",
        "momentum refers to looking one step back and make a decision that includes the slope there\n",
        "\n",
        "### parameter:\n",
        "generally you need to adjust the learning rate which is how much you change the parameters by at each step. \n",
        "keras.optimizers.Adam(lr=0.001)\n",
        "\n",
        "\n",
        "https://gitcdn.xyz/cdn/Tony607/blog_statics/e1a0b1e060e783bd1978a141acff897ae71bd021/images/optimizer/optimizer.gif"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MePeWiOJJsTi",
        "outputId": "8deac7b3-8a47-4c53-b172-fd2a36ae6ed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "# choose the optimizer and loss appropriately!\n",
        "model_digits64.compile(...."
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-46d60f191f85>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    model_digits64.compile(....\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwCCOxn1Juxl"
      },
      "source": [
        "print(model_digits64.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsWOelvIJun2"
      },
      "source": [
        "history64 = model_digits64.fit(x_train, x_train, \n",
        "                               validation_data=(x_test, x_test),\n",
        "                               epochs=..., batch_size=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJO05FMnRGtP"
      },
      "source": [
        "# always look at the loss!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhfIAie1Jucz"
      },
      "source": [
        "pl.plot(np.array(history64.history['loss']))\n",
        "pl.ylabel('loss')\n",
        "pl.xlabel('iteration')\n",
        "#pl.yscale('log')\n",
        "#pl.xscale('log')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnbDdWi4NxBj"
      },
      "source": [
        "The loss fuctionis plotted and because it is still decreasingn quite rapidly (slope of the curve not near 0 yet) I know I did not run enough epochs. Try and run for 200 epochs!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGTPRyFgRQTF"
      },
      "source": [
        "# predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7exTCDcJKhU_"
      },
      "source": [
        "output_image64 = model_digits64.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeFEGpTul4U6"
      },
      "source": [
        "def compareinout(i, outim, testimg, initialshape=(28,28)):\n",
        "  fig = pl.figure(figsize(10,5))\n",
        "  ax = fig.add_subplot(121) \n",
        "  ax.imshow(testimg[i].reshape(initialshape) , cmap=\"bone\")\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "  ax = fig.add_subplot(122) \n",
        "  ax.imshow(outim[i].reshape(initialshape) , cmap=\"bone\")\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3hzx41EKhOj"
      },
      "source": [
        "for i in range(10):\n",
        "  compareinout(i, output_image64, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whLydcJrM7t6"
      },
      "source": [
        "This is a rather bad result. Let me see if I can improve it . The images are too detailed. I can treat the problem as a binary problem to derice some detail. To approach a binary classifier I switch the activation function in the last layer to sigmoid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsvBeF_nSJTO"
      },
      "source": [
        "# change loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDXyqX7WKhHu"
      },
      "source": [
        "# choose the optimizer and loss appropriately!\n",
        "model_digits64_sig = Sequential()\n",
        "## encoder.....\n",
        "model_digits64_sig.add(Dense(ndim, activation=...\n",
        "model_digits64_sig.compile(optimizer=\"adadelta\", loss=..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbxiT8xdKhC8"
      },
      "source": [
        "history64_sig = model_digits64_sig.fit(x_train, x_train, \n",
        "                                       validation_data=(x_test, x_test), \n",
        "                                       epochs=..., batch_size=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQFxJHtbR2RV"
      },
      "source": [
        "pl.plot(np.array(history64_sig.history['loss']))\n",
        "pl.ylabel('loss')\n",
        "pl.xlabel('iteration')\n",
        "#pl.yscale('log')\n",
        "#pl.xscale('log')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZipOD2qLNYQq"
      },
      "source": [
        "The loss fuctionis plotted and because it is still decreasingn quite rapidly (slope of the curve not near 0 yet) I know I did not run enough epochs. Try and run for 200 epochs!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yOJ8s_xR2L3"
      },
      "source": [
        "output_image64_sig = model_digits64_sig.predict(x_test)\n",
        "for i in range(10):\n",
        "  compareinout(i, output_image64_sig, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A14pdeQNOb8"
      },
      "source": [
        "Much better! Let me choose a loss fuctio that is more appropriate for a nbinary classificaton."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBCGc4CLTXJ9"
      },
      "source": [
        "# sigmoid and binary cross entropy loss\n",
        "model_digits64_bce = model_digits64_sig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH8X_lDVTlCs"
      },
      "source": [
        "model_digits64_bce.compile(optimizer=\"adadelta\", loss=\"binary_crossentropy\")\n",
        "history64_bce = model_digits64_bce.fit(x_train, x_train, \n",
        "                                       validation_data=(x_test, x_test), \n",
        "                                       epochs=..., batch_size=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g94anP0NT4ET"
      },
      "source": [
        "pl.plot(np.array(history64_bce.history['loss']))\n",
        "pl.ylabel('loss')\n",
        "pl.xlabel('iteration')\n",
        "#pl.yscale('log')\n",
        "#pl.xscale('log')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4jlTB2zN_0Y"
      },
      "source": [
        "This loss fuction is also decreasing to steeply. Too few epochs!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HuqPELWT380"
      },
      "source": [
        "output_image64_bce = model_digits64_bce.predict(x_test)\n",
        "for i in range(10):\n",
        "  compareinout(i, output_image64_bce, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvSx1rU4OHrp"
      },
      "source": [
        "This is a pretty good result!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yWtDsH3T30C"
      },
      "source": [
        "pl.plot(np.array(history64.history['loss']), label=\"linear\")\n",
        "pl.plot(np.array(history64_sig.history['loss']), label=\"sigmoid\")\n",
        "pl.plot(np.array(history64_bce.history['loss']), label=\"bce\")\n",
        "pl.ylabel('loss')\n",
        "pl.xlabel('iteration')\n",
        "pl.legend()\n",
        "pl.title(\"the 3 loss functions\")\n",
        "pl.figure()\n",
        "pl.plot(np.array(history64.history['loss']), label=\"linear\")\n",
        "pl.plot(np.array(history64_sig.history['loss']), label=\"sigmoid\")\n",
        "pl.plot(np.array(history64_bce.history['loss']), label=\"bce\")\n",
        "pl.ylabel('loss')\n",
        "pl.xlabel('iteration')\n",
        "pl.xscale('log')\n",
        "pl.yscale('log')\n",
        "pl.legend()\n",
        "pl.title(\"the 3 loss functions, log scale\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXbrVpAUOeJF"
      },
      "source": [
        "All loss functions plotted: topin natural, bottomin logscale for enhanced visibility. It does not look like any of them is done learning (all decreasing rapidly still), especially the one for the the sigmoid-based mean square error loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWUnoBqkKg9K"
      },
      "source": [
        "# try more compression\n",
        "\n",
        "Now we shrink the bottle neck to 16 neurons: a much more ambitions model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXbjHrYSfwIP"
      },
      "source": [
        "model_digits = Sequential()\n",
        "#encoder...\n",
        "#bottle neck\n",
        "model_digits.add(Dense(16, activation='relu'))\n",
        "#decoder...\n",
        "model_digits.add(Dense(ndim, activation='sigmoid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6lGMsQki6RC"
      },
      "source": [
        "model_digits.compile(optimizer=\"adadelta\", loss=\"binary_crossentropy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QXiwgL0kPsy"
      },
      "source": [
        "print(model_digits.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65mlyV5hj8Od"
      },
      "source": [
        "history = model_digits.fit(x_train, x_train, epochs=200, batch_size=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAbZDuXOlCZi"
      },
      "source": [
        "pl.plot(np.array(history.history['loss']))\n",
        "pl.yscale('log')\n",
        "pl.xscale('log')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNcw-N9EPxib"
      },
      "source": [
        "the loss fuction: once again it did not finish learning. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31mTTaI4mCKw"
      },
      "source": [
        "output_image = model_digits.predict(x_test)\n",
        "\n",
        "for i in range(10):\n",
        "  compareinout(i, output_image, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_tHRpkkP1y8"
      },
      "source": [
        "The result is not bad! The decoder can recreate the image from only 16 numbers!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNcgMuEWd_m-"
      },
      "source": [
        "# Extract feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHA4zE6xmacQ"
      },
      "source": [
        "from keras import backend as K\n",
        "# input placeholder\n",
        "inp = model_digits.input                   \n",
        "# extract the bottle neck outputs\n",
        "outputs = model_digits.layers[3].output     \n",
        "# create a function to evaluate the output of the bottle neck layer for a given input\n",
        "functors = K.function([inp], [outputs])    \n",
        "\n",
        "# Testing\n",
        "layer_outs = functors(x_test[:1])\n",
        "pl.imshow(layer_outs[0]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR-aIb-XQQhY"
      },
      "source": [
        "This is the reducted representation of the first image in the test sample: a 16-values representation of the NxN pixel image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoT7vdpjWfk8"
      },
      "source": [
        "def compareinout_encoded(i, outim, testimg, initialshape=(28,28)):\n",
        "  fig = pl.figure(figsize(10,5))\n",
        "  ax = fig.add_subplot(131) \n",
        "  ax.imshow(testimg[i].reshape(initialshape) , cmap=\"bone\")\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "  ax = fig.add_subplot(132)\n",
        "  pl.imshow(functors(testimg[i:i+1])[0])\n",
        "  pl.yticks([])\n",
        "  ax = fig.add_subplot(133) \n",
        "  ax.imshow(outim[i].reshape(initialshape) , cmap=\"bone\")\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvFp8cTbcdKa"
      },
      "source": [
        "for i in range(10):\n",
        "  compareinout_encoded(i, output_image, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivBrwoxqddZv"
      },
      "source": [
        "*left*: original image\n",
        "\n",
        "*center*: compressed representation\n",
        "\n",
        "right: predicted image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GODceYH0DzfK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}